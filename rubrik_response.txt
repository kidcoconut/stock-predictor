>>>  Algorithm Understanding
Q1:  How does the Prophet Algorithm differ from an LSTM?
A1:  Prophet is specifically designed for the prediction of time-series data, and is an additive model, consisting of four components:  Yt = g(t) + s(t) + h(t) + e(t), where 
	- g(t) represents the general trend
	- s(t) is the seasonality component
	- h(t) is the holidays component, which have impacts on business results
	- e(t) is error, accounting for random fluctuations that cannot be explained by the model

	LSTM is a recurrent neural network (RNN) and stands for Long short-term memory.  LSTM the future from sequences of variable lengths, and is not constrained to time-series data alone.  LSTM cells learn the important parts of a sequence observed and discards the less important parts, through gates, which are functions with different learning objectives, such as:
	- how to compact the data (time series) observed so far
	- how to combine new input with prior series data
	- what data to forget and/or discard
	- what output should represent the prediction for the next step

	Prophet is specifically designed for business time series prediction. It achieves very good results for specific time series data, such as for the stock market, however it can fail spectacularly on time series datasets from other domains. In particular, for time series data where calendar dates do not apply, and where seasonal patterns cannot be learned. Prophetâ€™s advantage is that it requires less hyperparameters for tuning as it is specifically designed to detect patterns in business time series.

	LSTM-based RNNs are likely the most powerful approach to learning from sequential data, where time series is one special case. LSTM models benefit from massive datasets where complex patterns may be observed. Unlike Prophet, it does not rely on specific assumptions about the data such as time series stationarity or the existence of a Date field.  A disadvantage is that LSTM based RNNs are difficult to interpret and it is challenging to gain intuition into their behaviour. Careful hyperparameter tuning is also required in order to achieve good results.



Q2:  	Why does an LSTM have poor performance against ARIMA and Profit (Prophet?) for Time Series?
A2:	Although LSTM RNNs are quite powerful for application to time series predictions,  the model can have very poor performance against ARIMA and Prophet.  

This is likely due to LSTM's dependency on large datasets.  Otherwise, its relatively advanced nature lends itself easily to overfitting, despite the usage of regularization terms such as dropout.



>>>  Interview Readiness
Q3:  	What is exponential smoothing and why is it used in Time Series Forecasting?
A3:	Exponential smoothing is a broadly accurate method used for short-term forecasts. 

This technique assigns larger weights to more recent observations while assigning exponentially decreasing weights as the observations get increasingly distant.

Exponential smoothing is used in Time Series forecasted where a weighted distribution may be of benefit, where more recent data points is the series are more pertinent to the prediction that data that is relatively older.

There are a handful of Exponential Smoothing methods:  Simple, Double, and Triple.
	- Single:  Simple smoothing factor (alpha smoothing param); no consideration for trends, or seasonal patterns.  
	- Double:  Holt's trend, or second order smoothing (alpha plus beta, a decay param);  for linear trends but no seasonal patterns
	- Triple:  for data with linear trends and seasonal patterns (alpha, beta, plus gamma to comtrol the influence of seasonality);  Holt-Winters Exponential Smoothing
 which refer to the parameters in use, ie alpha (smoothing factor), 




Q4:  	What is stationarity? What is seasonality? Why Is Stationarity Important in Time Series Forecasting?
A4:	Stationarity can be simplistically described as a flat series, one without trend, with constant variance over time, with constant autocorrelation structure over time, and with no periodic fluctuations (ie seasonality).

Generally, stationarity refers to a series of data whose properties do not inherently depend on the timeframe within which the series is observed.  Mathematically, the statistical properties of the series (and/or underlying causes and processes) do not change over time.

Stationarity is an important concept (and goal) as several useful analytical tools and statistical tests and models rely on it.  The concept of stationarity is vital in order to know how to approach the data.  The accepted approach of managing non-stationary data is to remove it through various transformation techniques.  

Conversely, Seasonality is a recurring pattern at some time or event based frequency, whether annually, monthly, weekly, daily, or otherwise. 



Q5:  How is seasonality different from cyclicality? 
Seasonal effects are different from cyclical effects.  Seasonal cycles are observed by definition within one calendar year,  whereas cyclical effects can be observed across time periods shorter or longer than one calendar year. 


Fill in the blanks:
_A stationarized series_ is predictable, whereas _a seasonal or cyclical time-series_ is not.